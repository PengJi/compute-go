From 343ae45fabc861586bebd3da312a36a36681266c Mon Sep 17 00:00:00 2001
From: pengji <jipengpro@gmail.com>
Date: Tue, 30 Dec 2023 10:14:21 +0800
Subject: [PATCH] add new hypercall and add mmu walker

---
 arch/x86/kvm/mmu.c |  79 +++++++++++++++++++++++++++++++++
 arch/x86/kvm/mmu.h | 108 +++++++++++++++++++++++++++++++++++++++++++++
 arch/x86/kvm/x86.c |   5 +++
 arch/x86/kvm/x86.h |   1 +
 4 files changed, 193 insertions(+)

diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index f0b393dc7..40e7c4a74 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -6295,3 +6295,82 @@ void kvm_mmu_pre_destroy_vm(struct kvm *kvm)
 	if (kvm->arch.nx_lpage_recovery_thread)
 		kthread_stop(kvm->arch.nx_lpage_recovery_thread);
 }
+
+unsigned long gpa_from_guest, pxx_idx[PT64_ROOT_4LEVEL];
+// return msg to guest
+extern void write_to_shared_memory(const char *data, size_t size);
+
+static inline u64 print_huge_pte(u64 ent) {
+	u64 page_hpa = ent & PT64_DIR_BASE_ADDR_MASK,
+		offset_mask = PT64_LVL_OFFSET_MASK(2) | (PAGE_SIZE - 1),
+		*ptr = (u64*)(__va(page_hpa + (gpa_from_guest & offset_mask)));
+
+	pr_info("Huge Page (2M) at level 2 detected!");
+	pr_info("GPA " PTE_PATTERN, UL_TO_PTE(gpa_from_guest));
+	pr_info("HVA " VADDR_PATTERN, UL_TO_VADDR(*ptr));
+	pr_info("HPA " PTE_PATTERN, UL_TO_PTE((u64)page_hpa + (gpa_from_guest & offset_mask)));
+	pr_info("Value from guest: %llu\n" , *ptr);
+
+	return page_hpa + (gpa_from_guest & offset_mask);
+}
+
+static inline u64 print_pte(u64 ent) {
+	u64 page_hpa = ent & PT64_BASE_ADDR_MASK,
+		offset_mask = PAGE_SIZE - 1,
+		*ptr = (u64*)(__va(page_hpa + (gpa_from_guest & offset_mask))); // HVA to access data
+
+	pr_info("Normal Page (4k) at level 1 detected!");
+	pr_info("GPA   " PTE_PATTERN, UL_TO_PTE(gpa_from_guest));
+	pr_info("HVA   " VADDR_PATTERN, UL_TO_VADDR(*ptr));
+	pr_info("HPA   " PTE_PATTERN, UL_TO_PTE((u64)page_hpa + (gpa_from_guest & offset_mask)));
+	pr_info("Value from guest: %llu\n" , *ptr);
+
+	// TODO
+	char buffer[100];
+	snprintf(buffer, sizeof(buffer), "%llu", *ptr);
+	write_to_shared_memory(buffer, sizeof(buffer));
+
+	return page_hpa + (gpa_from_guest & offset_mask);
+}
+
+static u64 __mmu_guest_spte_walk(struct kvm_mmu_page *sp, int level)
+{
+	int i;
+
+	for (i = 0; i < PT64_ENT_PER_PAGE; ++i) {
+		u64 *ent = sp->spt;
+
+		if (is_shadow_present_pte(ent[i])) {
+			struct kvm_mmu_page *child;
+
+			if (i == pxx_idx[PT64_ROOT_4LEVEL - (5 - level)]) {
+				// fn(__pa(ent), ent[i], i, level);
+				if (!is_last_spte(ent[i], 5 - level)) {
+					child = page_header(ent[i] & PT64_BASE_ADDR_MASK);
+					__mmu_guest_spte_walk(child, level + 1);
+				} else {
+					if (is_large_pte(ent[i]))  // huge page
+						return print_huge_pte(ent[i]);
+					else                      // normal page
+						return print_pte(ent[i]);
+				}
+			}
+		}
+	}
+}
+
+u64 mmu_guest_spte_walk(struct kvm_vcpu *vcpu)
+{
+	int i;
+	struct kvm_mmu_page *sp;
+
+	if (!VALID_PAGE(vcpu->arch.mmu.root_hpa))
+		return -1;
+
+	if (vcpu->arch.mmu.root_level >= PT64_ROOT_4LEVEL) {
+		hpa_t root = vcpu->arch.mmu.root_hpa;  // EPT addr
+
+		sp = page_header(root);
+		return __mmu_guest_spte_walk(sp, 1);
+	}
+}
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index a8b75ef44..3a4b20d9d 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -220,4 +220,112 @@ int kvm_arch_write_log_dirty(struct kvm_vcpu *vcpu);
 int kvm_mmu_post_init_vm(struct kvm *kvm);
 void kvm_mmu_pre_destroy_vm(struct kvm *kvm);
 
+/* EPT walker functions */
+extern unsigned long gpa_from_guest, pxx_idx[PT64_ROOT_4LEVEL];
+u64 mmu_guest_spte_walk(struct kvm_vcpu *vcpu);
+
+/* convert to 12 bits */
+#define BYTE_TO_BINARY(byte) \
+  ((byte) & 0x80 ? '1' : '0'), ((byte) & 0x40 ? '1' : '0'),                    \
+  ((byte) & 0x20 ? '1' : '0'), ((byte) & 0x10 ? '1' : '0'),                    \
+  ((byte) & 0x08 ? '1' : '0'), ((byte) & 0x04 ? '1' : '0'),                    \
+  ((byte) & 0x02 ? '1' : '0'), ((byte) & 0x01 ? '1' : '0')
+
+/* convert to 3 bits */
+#define TBYTE_TO_BINARY(tbyte)  \
+  ((tbyte) & 0x04 ? '1' : '0'),    \
+  ((tbyte) & 0x02 ? '1' : '0'), ((tbyte) & 0x01 ? '1' : '0')
+
+/* page offset is 12 bits */
+#define UL_TO_PTE_OFFSET(ulong) \
+  TBYTE_TO_BINARY((ulong) >> 9), TBYTE_TO_BINARY((ulong) >> 6), \
+  TBYTE_TO_BINARY((ulong) >> 3), TBYTE_TO_BINARY((ulong))
+
+/* page index is 9 bits */
+#define UL_TO_PTE_INDEX(ulong) \
+  TBYTE_TO_BINARY((ulong) >> 6), TBYTE_TO_BINARY((ulong) >> 3), TBYTE_TO_BINARY((ulong))
+
+/* gva include 4 page index and 1 page offset */
+#define UL_TO_VADDR(ulong) \
+  UL_TO_PTE_INDEX((ulong) >> 39), UL_TO_PTE_INDEX((ulong) >> 30), \
+  UL_TO_PTE_INDEX((ulong) >> 21), UL_TO_PTE_INDEX((ulong) >> 12), \
+  UL_TO_PTE_OFFSET((ulong))
+
+/* convert unsigned long to pte */
+#define UL_TO_PTE_PHYADDR(ulong) \
+  BYTE_TO_BINARY((ulong) >> 32),    \
+  BYTE_TO_BINARY((ulong) >> 24), BYTE_TO_BINARY((ulong) >> 16), \
+  BYTE_TO_BINARY((ulong) >> 8), BYTE_TO_BINARY((ulong) >> 0)
+
+#define UL_TO_PTE_IR(ulong) \
+  UL_TO_PTE_OFFSET(ulong)
+
+#define UL_TO_PTE(ulong) \
+  UL_TO_PTE_IR((ulong) >> 52), UL_TO_PTE_PHYADDR((ulong) >> PAGE_SHIFT), UL_TO_PTE_OFFSET(ulong)
+
+#define UL_TO_PADDR(ulong) \
+  UL_TO_PTE_PHYADDR((ulong) >> PAGE_SHIFT), UL_TO_PTE_OFFSET(ulong)
+
+/* print pattern */
+#define TBYTE_TO_BINARY_PATTERN   "%c%c%c"  // 3 bits
+#define BYTE_TO_BINARY_PATTERN    "%c%c%c%c%c%c%c%c"  // 8 bits
+
+#define PTE_INDEX_PATTERN \
+  TBYTE_TO_BINARY_PATTERN TBYTE_TO_BINARY_PATTERN TBYTE_TO_BINARY_PATTERN " "
+
+#define VADDR_OFFSET_PATTERN \
+  TBYTE_TO_BINARY_PATTERN TBYTE_TO_BINARY_PATTERN \
+  TBYTE_TO_BINARY_PATTERN TBYTE_TO_BINARY_PATTERN
+
+#define VADDR_PATTERN \
+  PTE_INDEX_PATTERN PTE_INDEX_PATTERN \
+  PTE_INDEX_PATTERN PTE_INDEX_PATTERN \
+  VADDR_OFFSET_PATTERN
+
+// convert unsigned long to pte
+// 40 bits
+#define PTE_PHYADDR_PATTREN \
+  BYTE_TO_BINARY_PATTERN BYTE_TO_BINARY_PATTERN \
+  BYTE_TO_BINARY_PATTERN BYTE_TO_BINARY_PATTERN \
+  BYTE_TO_BINARY_PATTERN " "
+
+/* 12 bits */
+#define PTE_IR_PATTERN \
+  VADDR_OFFSET_PATTERN " "
+
+/* 12 + 40 + 12 bits */
+#define PTE_PATTERN \
+  PTE_IR_PATTERN PTE_PHYADDR_PATTREN VADDR_OFFSET_PATTERN
+
+#define PADDR_PATTERN \
+  PTE_PHYADDR_PATTREN VADDR_OFFSET_PATTERN
+
+static inline void print_gpa_from_guest(unsigned long a0) {
+	unsigned long mask = ((1 << PT64_PT_BITS) - 1);
+
+	gpa_from_guest = (unsigned long) a0;
+	pxx_idx[0] = (gpa_from_guest >> 39) & mask;  // PGD
+    pxx_idx[1] = (gpa_from_guest >> 30) & mask;  // PUD
+    pxx_idx[2] = (gpa_from_guest >> 21) & mask;  // PMD
+    pxx_idx[3] = (gpa_from_guest >> 12) & mask;  // PTE
+
+    // pr_info("idx %lu       %lu       %lu       %lu", pxx_idx[0], pxx_idx[1], pxx_idx[2], pxx_idx[3]);
+    pr_info("GPA [PGD IDX] [PUD IDX] [PMD IDX] [PTE IDX] [  Offset  ]");
+    pr_info("GPA "VADDR_PATTERN"\n", UL_TO_VADDR(gpa_from_guest));
+}
+
+// static inline void print_vaddr(volatile unsigned long *ptr) {
+//     unsigned long mask = ((1 << 9) - 1);
+
+//     vaddr = (unsigned long) ptr;
+//     pgd_idx = (vaddr >> 39) & mask;  // PGD
+//     pud_idx = (vaddr >> 30) & mask;  // PUD
+//     pmd_idx = (vaddr >> 21) & mask;  // PMD
+//     pte_idx = (vaddr >> 12) & mask;  // PTE
+
+//     pr_info("    %lu       %lu       %lu       %lu", pgd_idx, pud_idx, pmd_idx, pte_idx);
+//     pr_info("GVA [PGD IDX] [PUD IDX] [PMD IDX] [PTE IDX] [  Offset  ]");
+//     pr_info("GVA "VADDR_PATTERN"\n", UL_TO_VADDR(vaddr));
+// }
+
 #endif
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 614705b9d..c692681e5 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -7101,6 +7101,11 @@ int kvm_emulate_hypercall(struct kvm_vcpu *vcpu)
 	}
 
 	switch (nr) {
+	case KVM_HC_GUESTPING:
+		print_gpa_from_guest(a0);
+		mmu_guest_spte_walk(vcpu);
+		ret = 0;
+		break;
 	case KVM_HC_VAPIC_POLL_IRQ:
 		ret = 0;
 		break;
diff --git a/arch/x86/kvm/x86.h b/arch/x86/kvm/x86.h
index 587c39f32..1e6432891 100644
--- a/arch/x86/kvm/x86.h
+++ b/arch/x86/kvm/x86.h
@@ -13,6 +13,7 @@
 #define KVM_VMX_DEFAULT_PLE_WINDOW_MAX	UINT_MAX
 #define KVM_SVM_DEFAULT_PLE_WINDOW_MAX	USHRT_MAX
 #define KVM_SVM_DEFAULT_PLE_WINDOW	3000
+#define KVM_HC_GUESTPING 66
 
 static inline unsigned int __grow_ple_window(unsigned int val,
 		unsigned int base, unsigned int modifier, unsigned int max)
-- 
2.27.0

